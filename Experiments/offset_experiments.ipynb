{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/Code\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass  \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "from image_provider import ImageProvider\n",
    "from map_provider import MapProvider, ImageProjection\n",
    "from vector import Vector2D\n",
    "from WeightCalculators import AbsModelBasedWeightCalculator, ModelBasedWeightCalculator\n",
    "from ModelBuilders import MobileNetBuilder\n",
    "from tensorflow.keras import mixed_precision\n",
    "import json\n",
    "from WeightCalculators.Transformers import BaseTransformer, StretchedTanTransformer\n",
    "from color_generator import ColorGenerator\n",
    "from util import hex_color_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2080, compute capability 7.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 18:20:24.226452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:20:24.229724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:20:24.229871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:20:24.230239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "\n",
    "def enable_gpu_memory_growth():\n",
    "    \"\"\"\n",
    "    Enables memory growth mode for GPUs.\n",
    "    \"\"\"\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    assert len(gpus) > 0, \"No GPUs detected!\"\n",
    "            \n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "enable_gpu_memory_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now().strftime(\"%Y-%m-%d.%H-%M-%S\")\n",
    "run_folder = f\"Data/Offsets/{current_date}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Config Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drone crop size: 672\n",
      "City crop size: 672\n"
     ]
    }
   ],
   "source": [
    "base_size = 224\n",
    "crop_scale = 3\n",
    "drone_crop_delta = 0\n",
    "\n",
    "crop_size = math.floor(base_size * crop_scale)\n",
    "print(f\"Drone crop size: {crop_size + drone_crop_delta}\")\n",
    "print(f\"City crop size: {crop_size}\")\n",
    "\n",
    "graph_size = 1500\n",
    "target_distances = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 75, 100, 150, 250, 350, 500, 700, 1000]\n",
    "images_threshold = 0.66\n",
    "\n",
    "# model_builder = EfficientNetB2Builder(second_dense=8, weight_file=\"enB2-e8-s59-b1-rloss.h5\")\n",
    "# model_builder = ResNetBuilder(second_dense=8, weight_file=\"resnet50-e1-s80-b1-rloss.h5\")\n",
    "model_builder = MobileNetBuilder(second_dense=8, weight_file=\"trainall-d64-e4-s35-b1-rloss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_image = ImageProvider(\"City/NewCut/City_2017.jpg\")\n",
    "drone_image = ImageProvider(\"City/NewCut/City_2016.jpg\")\n",
    "\n",
    "projection = None # ImageProjection(Vector2D(8000, 8000), Vector2D(6117, 5281))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_offset_points(offset: int):\n",
    "    vector_offsets = [\n",
    "        Vector2D(offset, 0),\n",
    "        Vector2D(0, offset),\n",
    "        Vector2D(-offset, 0),\n",
    "        Vector2D(0, -offset)\n",
    "    ]\n",
    "\n",
    "    def round_up(number):\n",
    "        floored = math.floor(number)\n",
    "        return floored if number - floored < 0.5 else floored + 1\n",
    "\n",
    "    offset = round_up(math.sqrt((offset ** 2) / 2))\n",
    "    side_offsets = [\n",
    "        Vector2D(offset, offset),\n",
    "        Vector2D(offset, -offset),\n",
    "        Vector2D(-offset, offset),\n",
    "        Vector2D(-offset, -offset)\n",
    "    ]\n",
    "\n",
    "    vector_offsets.extend(side_offsets)\n",
    "\n",
    "    return vector_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferencePoint:\n",
    "    def __init__(self, point: Vector2D, label: str = \"\"):\n",
    "        self.point = point\n",
    "        self.label = label\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Human-readable string representation of the vector.\"\"\"\n",
    "\n",
    "        return f'{self.label} - ({self.point.x}, {self.point.y})'\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Unambiguous string representation of the vector.\"\"\"\n",
    "\n",
    "        return self.__str__()\n",
    "\n",
    "def generate_reference_points():\n",
    "    reference_points = [\n",
    "        ReferencePoint(Vector2D(5881, 1656), 'forest'),\n",
    "        ReferencePoint(Vector2D(15650, 24030), 'forest'),\n",
    "        ReferencePoint(Vector2D(8650, 2000), 'forest'),\n",
    "        ReferencePoint(Vector2D(5846, 4752), 'apartments'),\n",
    "        ReferencePoint(Vector2D(8046, 19828), 'apartments'),\n",
    "        ReferencePoint(Vector2D(3330, 9590), 'apartments'),\n",
    "        ReferencePoint(Vector2D(5310, 7960), 'apartments'),\n",
    "        ReferencePoint(Vector2D(2501, 3402), 'apartments'),\n",
    "        ReferencePoint(Vector2D(1973, 22699), 'field'),\n",
    "        ReferencePoint(Vector2D(4780, 4160), 'road'),\n",
    "        ReferencePoint(Vector2D(14130, 1500), 'road'),\n",
    "        ReferencePoint(Vector2D(24230, 10280), 'river'),\n",
    "        ReferencePoint(Vector2D(9960, 16340), 'small buildings'),\n",
    "        ReferencePoint(Vector2D(7781, 5645), 'forest & road'),\n",
    "        ReferencePoint(Vector2D(25000, 24570), 'forest & road'),\n",
    "        ReferencePoint(Vector2D(9250, 20580), 'apartments & roads'),\n",
    "        ReferencePoint(Vector2D(25678, 13083), 'apartments & small buildings'),\n",
    "        ReferencePoint(Vector2D(18543, 9141), 'apartments & forest'),\n",
    "        ReferencePoint(Vector2D(3298, 25260), 'road & field'),\n",
    "        ReferencePoint(Vector2D(2013, 3788), 'road & small buildings'),\n",
    "    ]\n",
    "\n",
    "    return reference_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_points():\n",
    "    for x, y in city_map.generate_random_locations(10):\n",
    "        x += 1000 if x < 1500 else 0\n",
    "        x -= 1000 if x > 25000 else 0\n",
    "\n",
    "        y += 1000 if y < 1500 else 0\n",
    "        y -= 1000 if y > 25000 else 0\n",
    "\n",
    "        print(f\"ReferencePoint(Vector2D({x}, {y}), ''),\")\n",
    "\n",
    "# generate_random_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Anchor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_reference_points():\n",
    "    for reference_point in generate_reference_points():\n",
    "        display(f\"Showcase for point: {reference_point}\")\n",
    "        anchor =  drone_map.get_cropped_image(reference_point.point.x, reference_point.point.y)\n",
    "\n",
    "        display(Image.fromarray(anchor))\n",
    "\n",
    "# show_reference_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_map = MapProvider(\n",
    "    image_provider=city_image,\n",
    "    crop_size=crop_size,\n",
    "    projection=projection)\n",
    "\n",
    "drone_map = MapProvider(\n",
    "    image_provider=drone_image,\n",
    "    crop_size=crop_size + drone_crop_delta,\n",
    "    projection=projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 18:20:59.231064: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-07 18:20:59.234686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:20:59.234886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:20:59.235016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:21:00.206408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:21:00.206582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:21:00.206715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 18:21:00.206829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6103 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:2b:00.0, compute capability: 7.5\n",
      "2022-05-07 18:21:00.606299: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-05-07 18:21:00.606317: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-05-07 18:21:00.606338: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1630] Profiler found 1 GPUs\n",
      "2022-05-07 18:21:00.703089: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-05-07 18:21:00.704038: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "model_calculator = AbsModelBasedWeightCalculator(\n",
    "    model_builder,\n",
    "    batch_size=64, \n",
    "    transformer=StretchedTanTransformer(images_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Data Dump/Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asBase64(image_np):\n",
    "    image = Image.fromarray(image_np)\n",
    "    \n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode('ascii')\n",
    "\n",
    "    return img_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_results(anchor, offset_data: OffsetData):\n",
    "    display(\"----------------------------------------------\")\n",
    "\n",
    "    display(f\"Offset: {offset_data.vector_offset}.\")\n",
    "    display(f\"Distance: {offset_data.real_distance}\")\n",
    "\n",
    "    display(f\"Weight: {offset_data.weight}.\")\n",
    "    display(f\"Delta: {offset_data.delta:.4f}\")\n",
    "\n",
    "\n",
    "    images = HTML(f\"\"\"\n",
    "        <div class=\"row\">\n",
    "            <img src=data:image/jpeg;base64,{asBase64(anchor)} style=\"height:300px\"/>\n",
    "            <img src=data:image/jpeg;base64,{asBase64(offset_data.offset_image)} style=\"height:300px\"/>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "\n",
    "    display(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class OffsetData:\n",
    "    reference_point: ReferencePoint\n",
    "    vector_offset: Vector2D\n",
    "    original_weight: float\n",
    "    weight: float\n",
    "    offset_image: np.ndarray\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.delta = self.weight - self.original_weight\n",
    "        self.real_distance =  self.reference_point.point.distance_to(self.reference_point.point + self.vector_offset)\n",
    "\n",
    "    def dump(self):\n",
    "        return {\n",
    "            \"offset\": f\"{self.vector_offset}\",\n",
    "            \"real_distance\": self.real_distance,\n",
    "            \"weight\": self.weight,\n",
    "            \"delta\": self.delta,\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class DistanceData:\n",
    "    target_distance: int\n",
    "    offsets: list[OffsetData]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.avg_delta = statistics.mean([offset.delta for offset in self.offsets])\n",
    "        self.avg_weight = statistics.mean([offset.weight for offset in self.offsets])\n",
    "        self.offsets_dump = [offset.dump() for offset in self.offsets]\n",
    "\n",
    "    def dump(self):\n",
    "        return {\n",
    "            \"target_distance\": f\"{self.target_distance}\",\n",
    "            \"avg_weight\": self.avg_weight,\n",
    "            \"avg_delta\": self.avg_delta,\n",
    "            \"offsets\": self.offsets_dump\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class PointData:\n",
    "    reference_point: ReferencePoint\n",
    "    original_weight: float\n",
    "    anchor_image: np.ndarray\n",
    "    distances: list[DistanceData]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.avg_delta = statistics.mean([distance.avg_delta for distance in self.distances])\n",
    "        self.distances_dump = [distance.dump() for distance in self.distances]\n",
    "\n",
    "    def dump(self):\n",
    "        return {\n",
    "            \"label\": self.reference_point.label,\n",
    "            \"reference_point\": f\"{self.reference_point.point}\",\n",
    "            \"original_weight\": self.original_weight,\n",
    "            \"avg_delta\": self.avg_delta,\n",
    "            \"distances\": self.distances_dump\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    reference_points = generate_reference_points()\n",
    "\n",
    "    point_dump = []\n",
    "    for reference_point in reference_points:\n",
    "        display(f\"TEST for point: {reference_point}\")\n",
    "\n",
    "        anchor =  drone_map.get_cropped_image(reference_point.point.x, reference_point.point.y)\n",
    "        positive = city_map.get_cropped_image(reference_point.point.x, reference_point.point.y)\n",
    "        weights = model_calculator.create_normalized_weights_from_images(anchor, [positive])\n",
    "        original_weight = weights[0]\n",
    "\n",
    "        display(f\"Initial positive weight: {original_weight}\")\n",
    "\n",
    "        distances_dump = []\n",
    "        for distance in target_distances:\n",
    "            vector_offsets = generate_offset_points(distance)\n",
    "\n",
    "            offset_points = [reference_point.point + vector_offset for vector_offset in vector_offsets]\n",
    "            offset_particles = [(offset_point.x, offset_point.y) for offset_point in offset_points]\n",
    "\n",
    "            offset_images = city_map.create_images_from_particles_threaded(offset_particles, 2)\n",
    "            weights = model_calculator.create_normalized_weights_from_images(anchor, offset_images)\n",
    "\n",
    "            offsets_dump = []\n",
    "            for (weight, vector_offset, offset_image) in zip(weights, vector_offsets, offset_images):\n",
    "                offset_data = OffsetData(\n",
    "                    reference_point = reference_point,\n",
    "                    vector_offset = vector_offset,\n",
    "                    original_weight = original_weight,\n",
    "                    weight = weight,\n",
    "                    offset_image = offset_image\n",
    "                )\n",
    "                \n",
    "                offsets_dump.append(offset_data)\n",
    "                #dump_results(anchor, offset_data)\n",
    "\n",
    "            distance_data = DistanceData(target_distance=distance, offsets=offsets_dump)\n",
    "            distances_dump.append(distance_data)\n",
    "\n",
    "        point_data = PointData(\n",
    "            reference_point=reference_point,\n",
    "            original_weight=original_weight,\n",
    "            anchor_image=anchor,\n",
    "            distances=distances_dump)\n",
    "        \n",
    "        point_dump.append(point_data)\n",
    "\n",
    "    return point_dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TEST for point: forest - (5881, 1656)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 18:21:01.940966: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.8146882738385881'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: forest - (15650, 24030)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.9023764084796516'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: forest - (8650, 2000)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.8826840069829202'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: apartments - (5846, 4752)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.8234975386639031'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: apartments - (8046, 19828)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.7855752244287608'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: apartments - (3330, 9590)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.8197187890811842'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: apartments - (5310, 7960)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.7892367109960439'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: apartments - (2501, 3402)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.8011007503587373'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: field - (1973, 22699)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.8742583527856944'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: road - (4780, 4160)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.8742537595787827'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: road - (14130, 1500)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.8576767298640037'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: river - (24230, 10280)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.8498402225727938'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: small buildings - (9960, 16340)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.8066733613306163'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: forest & road - (7781, 5645)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.9297674724033901'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: forest & road - (25000, 24570)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.7333560671125139'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: apartments & roads - (9250, 20580)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.8731810706002372'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: apartments & small buildings - (25678, 13083)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.8099298671800264'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: apartments & forest - (18543, 9141)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.7539762574799207'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: road & field - (3298, 25260)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.9306931787607621'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TEST for point: road & small buildings - (2013, 3788)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Initial positive weight: 0.8881467313182597'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "point_dump = run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"font-family: monospace\">apartments <span style=\"color: #8e44ad\">████</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"font-family: monospace\">road <span style=\"color: #34495e\">████</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"font-family: monospace\">small buildings <span style=\"color: #c0392b\">████</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"font-family: monospace\">field <span style=\"color: #f1c40f\">████</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"font-family: monospace\">forest <span style=\"color: #16a085\">████</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"font-family: monospace\">river <span style=\"color: #3498db\">████</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_colors = {\n",
    "    'apartments': '#8e44ad',\n",
    "    'road': '#34495e',\n",
    "    'small buildings': '#c0392b',\n",
    "    'field': '#f1c40f',\n",
    "    'forest': '#16a085',\n",
    "    'river': '#3498db',\n",
    "}\n",
    "\n",
    "for label, color in label_colors.items():\n",
    "    hex_color_dump(color, label)\n",
    "\n",
    "color_generator = ColorGenerator(\"#2c3e50\", label_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggregatedData:\n",
    "    def __init__(self, target_distance: int, distances_dump: list[DistanceData]):\n",
    "        self.target_distance = target_distance\n",
    "        self.avg_weight = statistics.mean([distance_data.avg_weight for distance_data in distances_dump])\n",
    "        self.avg_delta = statistics.mean([distance_data.avg_delta for distance_data in distances_dump])\n",
    "        self.min_weight = min([distance_data.avg_weight for distance_data in distances_dump])\n",
    "\n",
    "    def dump(self):\n",
    "        return {\n",
    "            \"target_distance\": self.target_distance,\n",
    "            \"avg_weight\": self.avg_weight,\n",
    "            \"avg_delta\": self.avg_delta,\n",
    "            \"min_weight\": self.min_weight,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointGraphGenerator:\n",
    "    def __init__(self, label: str, transformer: BaseTransformer, y_ticks: list[float], separator_line: float, colored):\n",
    "        self.label = label\n",
    "        self.distances = [0] + target_distances\n",
    "        self.target_max = max(target_distances)\n",
    "        self.separator_line = separator_line\n",
    "        self.y_ticks = y_ticks\n",
    "        self.colored = colored\n",
    "\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def _generate_graph_base(self):\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(16, 5)\n",
    "\n",
    "        ax.set_xlabel(\"Distance (px)\")\n",
    "        ax.set_ylabel(\"Weights\")\n",
    "\n",
    "        ax.set_xlim([0, self.target_max + 1])\n",
    "        ax.set_xticks(np.arange(0, self.target_max + 1, 25))\n",
    "\n",
    "        if self.y_ticks is not None:\n",
    "            ax.set_yticks(self.y_ticks)\n",
    "\n",
    "        if self.separator_line is not None:\n",
    "            ax.plot([0, self.target_max], [self.separator_line, self.separator_line], color='r', alpha=0.8)\n",
    "\n",
    "        return fig, ax\n",
    "\n",
    "    def generate_distance_graph(self, data: PointData):\n",
    "        fig, ax = self._generate_graph_base()\n",
    "        transformer = self.transformer\n",
    "\n",
    "        weight_data = [transformer.transform(data.original_weight)] + [transformer.transform(distance.avg_weight) for distance in data.distances]\n",
    "        ax.plot(self.distances, weight_data, marker=\"o\")\n",
    "\n",
    "        return fig, ax\n",
    "\n",
    "    def generate_aggregated_graph(self, point_dump: list[PointData], aggregated_dump: list[AggregatedData]):\n",
    "        fig, ax = self._generate_graph_base()\n",
    "        transformer = self.transformer\n",
    "\n",
    "        for point_data in point_dump:\n",
    "            if self.colored:\n",
    "                label = point_data.reference_point.label\n",
    "                data_color = color_generator.label_to_color(point_data.reference_point.label)\n",
    "                alpha = 0.40\n",
    "            else:\n",
    "                label = \"runs\"\n",
    "                data_color = \"k\"\n",
    "                alpha = 0.15\n",
    "\n",
    "            weight_data = [transformer.transform(point_data.original_weight)] + [transformer.transform(distance.avg_weight) for distance in point_data.distances]\n",
    "            ax.plot(self.distances, weight_data, color=data_color, alpha=alpha, label=label)\n",
    "\n",
    "        average_reference_weight = statistics.mean([point_data.original_weight for point_data in point_dump])\n",
    "        total_weight_data = [transformer.transform(average_reference_weight)] + [transformer.transform(aggregate.avg_weight) for aggregate in aggregated_dump]\n",
    "        \n",
    "        ax.plot(self.distances, total_weight_data, marker='o', label=\"avg\")\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        labels = [f\"{label} x{labels.count(label)}\" if label != \"avg\" else label for label in by_label.keys()]\n",
    "\n",
    "        lgd = ax.legend(by_label.values(), labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "        return fig, ax, lgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointDataSaver:\n",
    "    def __init__(self, colored_graphs=False):\n",
    "        self.linear_graph_generator = PointGraphGenerator(\"linear\", BaseTransformer(), np.arange(0, 1.01, 0.05), images_threshold, colored_graphs)\n",
    "        self.log_graph_generator = PointGraphGenerator(\"log\", StretchedTanTransformer(images_threshold), np.arange(0, 100, 5), 0, colored_graphs)\n",
    "\n",
    "    def _build_point_folder(self, point: Vector2D):\n",
    "        point_dir = f\"{run_folder}/{point}\"\n",
    "        os.makedirs(point_dir, exist_ok=True)\n",
    "\n",
    "        return point_dir\n",
    "\n",
    "    def _save_stats(self, point_folder: str, data: PointData):\n",
    "        point_file = f\"{point_folder}/point-stats.json\"\n",
    "\n",
    "        with open(point_file, \"w\") as file:\n",
    "            file.write(json.dumps(data.dump(), indent=4))\n",
    "\n",
    "    def _save_images(self, point_folder: str, data: PointData):\n",
    "        images_folder = f\"{point_folder}/images\"\n",
    "        os.makedirs(images_folder, exist_ok=True)\n",
    "\n",
    "        Image.fromarray(data.anchor_image).save(f\"{images_folder}/anchor.jpg\")\n",
    "\n",
    "        for distance in data.distances:\n",
    "            distance_folder = f\"{images_folder}/{distance.target_distance}\"\n",
    "            os.makedirs(distance_folder, exist_ok=True)\n",
    "\n",
    "            for offset in distance.offsets:\n",
    "                file_name = f\"{distance_folder}/{offset.vector_offset}.jpg\"\n",
    "                Image.fromarray(offset.offset_image).save(file_name)\n",
    "\n",
    "    def _save_individual_graphs(self, graph_generator: PointGraphGenerator, point_folder: str, data: PointData):\n",
    "        fig, ax = graph_generator.generate_distance_graph(data)\n",
    "        fig.savefig(f\"{point_folder}/{graph_generator.label}_regular_graph.png\", bbox_inches='tight', facecolor='w', dpi=300)\n",
    "\n",
    "        ax.set_xlim([0, 150])\n",
    "        ax.set_xticks(np.arange(0, 151, 5))\n",
    "\n",
    "        fig.savefig(f\"{point_folder}/{graph_generator.label}_zoomed_graph.png\", bbox_inches='tight', facecolor='w', dpi=300)\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "    def _save_normalized_graph(self, point_folder: str, data: PointData):\n",
    "        normalized_fig, ax = self.linear_graph_generator.generate_distance_graph(data)\n",
    "\n",
    "        ax.set_ylim([0, 1.01])\n",
    "        ax.set_yticks(np.arange(0, 1.01, 0.05))\n",
    "\n",
    "        normalized_fig.savefig(f\"{point_folder}/linear_normalized_graph.png\", bbox_inches='tight', facecolor='w', dpi=300)\n",
    "\n",
    "        plt.close(normalized_fig)\n",
    "\n",
    "    def _save_individual(self, data: PointData):\n",
    "        point_folder = self._build_point_folder(data.reference_point)\n",
    "        \n",
    "        self._save_stats(point_folder, data)\n",
    "        self._save_images(point_folder, data)\n",
    "        \n",
    "        self._save_individual_graphs(self.linear_graph_generator, point_folder, data)\n",
    "        self._save_individual_graphs(self.log_graph_generator, point_folder, data)\n",
    "        self._save_normalized_graph(point_folder, data)\n",
    "\n",
    "    def _get_aggregated_dump(self, point_dump: list[PointData]) -> list[AggregatedData]:\n",
    "        aggregated_distance_data = {}\n",
    "        for target_distance in target_distances:\n",
    "            aggregated_distance_data[target_distance] = []\n",
    "            \n",
    "        for point_data in point_dump:\n",
    "            for distance_data in point_data.distances:\n",
    "                aggregated_distance_data[distance_data.target_distance].append(distance_data)\n",
    "\n",
    "        aggregated_dump =  [AggregatedData(target_distance, dumps) for target_distance, dumps in aggregated_distance_data.items()]\n",
    "\n",
    "        return aggregated_dump\n",
    "\n",
    "    def _save_aggregated(self, point_dump: list[PointData], aggregated_dump: list[AggregatedData]):\n",
    "        all_run_data = {\n",
    "            \"threshold\": images_threshold,\n",
    "            \"avg_reference_weight\": statistics.mean([point_data.original_weight for point_data in point_dump]),\n",
    "            \"targets\": [aggregate.dump() for aggregate in aggregated_dump],\n",
    "        }\n",
    "\n",
    "        aggregate_file = f\"{run_folder}/run-stats.json\"\n",
    "\n",
    "        with open(aggregate_file, \"w\") as file:\n",
    "            file.write(json.dumps(all_run_data, indent=4))\n",
    "\n",
    "    def _save_aggregated_graphs(self, graph_generator: PointGraphGenerator, point_dump: PointData, aggregated_dump: list[AggregatedData]):\n",
    "        fig, ax, lgd = graph_generator.generate_aggregated_graph(point_dump, aggregated_dump)\n",
    "        fig.savefig(f\"{run_folder}/{graph_generator.label}_regular_graph.png\", bbox_extra_artists=(lgd,), bbox_inches='tight', facecolor='w', dpi=300)\n",
    "\n",
    "        ax.set_xlim([0, 150])\n",
    "        ax.set_xticks(np.arange(0, 151, 5))\n",
    "\n",
    "        fig.savefig(f\"{run_folder}/{graph_generator.label}_zoomed_graph.png\", bbox_extra_artists=(lgd,), bbox_inches='tight', facecolor='w', dpi=300)\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "    def save_all_individual(self, point_dump: list[PointData]):\n",
    "        for point_data in point_dump:\n",
    "            self._save_individual(point_data)\n",
    "\n",
    "    def save_all_aggregated(self, point_dump: list[PointData]):\n",
    "        aggregated_dump =  self._get_aggregated_dump(point_dump)\n",
    "        self._save_aggregated(point_dump, aggregated_dump)\n",
    "        \n",
    "        self._save_aggregated_graphs(self.linear_graph_generator, point_dump, aggregated_dump)\n",
    "        self._save_aggregated_graphs(self.log_graph_generator, point_dump, aggregated_dump)\n",
    "\n",
    "point_data_saver = PointDataSaver(colored_graphs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_data_saver.save_all_individual(point_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_data_saver.save_all_aggregated(point_dump)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
